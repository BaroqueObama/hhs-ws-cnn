{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GM 9: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Typical libraries for data science\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # graphing\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "# transform is used to convert data into Tensor form with transformations\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# libraries to generate Random Subset & dataLoader to feed Batch of data to model, as feeding whole dataset may lead to System failure or Hang\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# this will help us to create Grid of images\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Neural Network we have to perform Data Normalization to reduce possibility of Over Fitting, also CNN algorithms use Gradient boosting, So its must to perform Normalization else some variable may be given higher weightage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    # To resize image\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    # To normalize image\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "root = './data',\n",
    "train = True,\n",
    "download = True,\n",
    "transform = trans\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "root = './data',\n",
    "train = False,\n",
    "download = True,\n",
    "transform = trans\n",
    ")\n",
    "\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets observe some changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = train_set[0]\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have images with 32*32 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_img(img, label):\n",
    "    print('Label: ', label)\n",
    "    plt.imshow(img.permute(1,2,0), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As torch has image representation as [color channel, Height, Width] but Maplotlib accepts [height, width, color channel], hence above .permute() function does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_img(*train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_img(*train_set[9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_img(*test_set[5999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validation data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function will generate random indexes between 0 and 59999\n",
    "def split_indices(n, val_per, seed = 0):\n",
    "    n_val = int(n * val_per)\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(n)\n",
    "    return idx[n_val : ], idx[: n_val]\n",
    "\n",
    "\n",
    "val_per = 0.2\n",
    "rand_seed = 42\n",
    "\n",
    "train_indices, val_indices = split_indices(len(train_set), val_per, rand_seed)\n",
    "\n",
    "print(len(train_indices), len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets plot some indexes\n",
    "print(\"Validation Indices: \", val_indices[:20])\n",
    "print(\"Training Indices: \", train_indices[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems indexes are distributed across range as provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is one of Hyper parameter, but let's select given below value\n",
    "batch_size = 512\n",
    "\n",
    "# training data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(train_set, batch_size, sampler = train_sampler)\n",
    "\n",
    "# validation dataloader\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_dl = DataLoader(train_set, batch_size, sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify where we have all class from output columns in both train and validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will select first 110 image from first batch of size = 512\n",
    "def show_batch(dl):\n",
    "    for img, label in dl:\n",
    "        fig, ax = plt.subplots(figsize = (12,8))\n",
    "        ax.imshow(make_grid(img[:110], 10).permute(1,2,0))\n",
    "        break\n",
    "        \n",
    "show_batch(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images seems equally Distributed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building using Torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how Yen LeKun has decribed and built First Neural network in 1988, that was probably first working Neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size = 2),\n",
    "            nn.Conv2d(6, 16, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size = 2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, num_classes)  \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logit = self.classifier(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = LeNet5(num_classes = 10)\n",
    "\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test model based on initial Guesses by Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = next(iter(train_set))\n",
    "img = sample[0]\n",
    "out = model(img.unsqueeze(0))\n",
    "# Output In terms of Probability\n",
    "F.softmax(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial guess from model suggest, probability of each class as 10%, which is kind of 1st prediction from model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets plot\n",
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it was wrong guess from Model :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using GPU, so below code will help us to access GPU at different stage of Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, x, y, opt = None, metric = None):\n",
    "    \n",
    "    pred = model(x)\n",
    "    \n",
    "    loss = loss_func(pred, y)\n",
    "    \n",
    "    if opt is not None:\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    \n",
    "    if metric is not None:\n",
    "        \n",
    "        metric_result = metric(pred, y)\n",
    "        \n",
    "    return loss.item(), len(x), metric_result\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, loss_fn, val_dl, metric = None):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        results = [loss_batch(model, loss_fn, x, y, metric = metric) for x, y in val_dl]\n",
    "        \n",
    "        losses, nums, metrics = zip(*results)\n",
    "        \n",
    "        total = np.sum(nums)\n",
    "        \n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "        \n",
    "        avg_metric = None\n",
    "        \n",
    "        if metric is not None:\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
    "            \n",
    "    return avg_loss, total, avg_metric\n",
    "\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_fn, train_dl, val_dl, opt_fn = None, metric = None, scheduler = None, scheduler_on = 'val_metric'):\n",
    "    \n",
    "    train_losses, val_losses, val_metrics, train_metrics = [], [], [], []\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        for x, y in train_dl:\n",
    "            train_loss, _, train_metric = loss_batch(model, loss_fn, x, y, opt_fn, metric)\n",
    "            \n",
    "        model.eval()\n",
    "        result = evaluate(model, loss_fn, val_dl, metric)\n",
    "        val_loss, total, val_metric = result\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_metrics.append(val_metric)\n",
    "        train_metrics.append(train_metric)\n",
    "        \n",
    "        if metric is None:\n",
    "            print('Epoch{}/{}, train_loss: {:.4f}, val_loss: {:.4f}' \n",
    "                 .format(epoch+1, epochs, train_loss, val_loss))\n",
    "            \n",
    "        else:\n",
    "            print('Epoch {}/{}, train_loss: {:.4f}, val_loss: {:.4f}, val_{}: {:.4f}, train_{}: {:.4f}'\n",
    "                 .format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric, metric.__name__, train_metric))\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            if scheduler_on == 'val_metric':\n",
    "                scheduler.step(val_metrics[-1])\n",
    "        \n",
    "            \n",
    "    return train_losses, val_losses, val_metrics, train_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    _, preds = torch.max(output, dim = 1)\n",
    "    \n",
    "    return torch.sum(preds == labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial guess on Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss, _, val_acc = evaluate(model, F.cross_entropy, val_dl, metric = accuracy)\n",
    "\n",
    "print(\"Initial Validation Losses: {}, Accuracy: {}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, mode = 'max', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, optimizer, accuracy, scheduler, 'val_metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.plot(history[0], '-go')\n",
    "plt.plot(history[1], '-yx')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Plot between Validation Loss & training Loss vs Epochs')\n",
    "plt.legend(['Train Loss', 'Validation Loss'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.plot(history[3], '-go')\n",
    "plt.plot(history[2], '-yx')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Plot between Training Accuracy & Validation vs Epochs')\n",
    "plt.legend(['Train Accuracy', 'Validation Accuracy'], loc = 'lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data & Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = test_set[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = test_set[1839]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = test_set[193]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = test_set[1000]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a final step, let's also look at the overall loss and accuracy of the model on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader = DeviceDataLoader(DataLoader(test_set, batch_size=256), device)\n",
    "result = evaluate(model, F.cross_entropy, test_loader, metric = accuracy)\n",
    "result\n",
    "Accuracy = result[2] * 100\n",
    "Accuracy\n",
    "loss = result[0]\n",
    "print(\"Total Losses: {}, Accuracy: {}\".format(loss, Accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
